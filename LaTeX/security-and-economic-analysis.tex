\section{Security and Economic Analysis}

\subsection{Game Theoretic Model}

We model the OraSRS protocol as a game between three types of players: honest nodes ($H$), malicious nodes ($M$), and lazy validators ($L$). The security of our system relies on ensuring that honest behavior constitutes a Nash equilibrium.

\subsubsection{Payoff Matrix}

Let us define the following variables:
\begin{itemize}
\item $C_{stake}$: Cost of staking tokens to participate as a validator
\item $C_{commit}$: Cost of computation and bandwidth to submit threat intelligence
\item $B_{attack}$: Benefit gained from a successful attack
\item $P_{slash}$: Penalty from being caught and slashed for malicious behavior
\item $R_{reward}$: Reward for honest threat reporting and verification
\end{itemize}

The payoff matrix for a single node choosing between honest reporting ($H$), malicious reporting ($M$), and lazy validation ($L$) is shown in Table~\ref{tab:payoff_matrix}.

\begin{table}[H]
\centering
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Strategy} & \textbf{Expected Payoff} & \textbf{Risk} & \textbf{Net Utility} \\
\midrule
Honest ($H$) & $R_{reward} - C_{commit}$ & $0$ & $R_{reward} - C_{commit}$ \\
Malicious ($M$) & $B_{attack} - C_{stake} - C_{commit}$ & $P_{slash}$ & $B_{attack} - C_{stake} - C_{commit} - P_{slash}$ \\
Lazy ($L$) & $-C_{commit}$ & Reputation penalty & $-C_{commit} - R_{penalty}$ \\
\bottomrule
\end{tabular}
\caption{Payoff Matrix for OraSRS Node Strategies}
\label{tab:payoff_matrix}
\end{table}

\subsubsection{Economic Security Proof}

For the system to be secure, the following conditions must hold:

\begin{theorem}
\textbf{Economic Security Condition}: Honest reporting is an equilibrium strategy when:
$$C_{stake} + C_{commit} > B_{attack}$$
\end{theorem}

\begin{proof}
For a rational node to choose honest reporting over malicious reporting, the following inequality must hold:

$$U(H) > U(M)$$

Where $U(H)$ is the utility of honest behavior and $U(M)$ is the utility of malicious behavior.

$$R_{reward} - C_{commit} > B_{attack} - C_{stake} - C_{commit} - P_{slash}$$

Simplifying:

$$R_{reward} + C_{stake} + P_{slash} > B_{attack}$$

Since $R_{reward} > 0$ and $P_{slash} > 0$, it follows that the condition $C_{stake} > B_{attack} - R_{reward} - P_{slash}$ ensures honest behavior is preferred. However, to ensure strong disincentive for attacks even with minimal rewards/punishments, we require:

$$C_{stake} + C_{commit} > B_{attack}$$
\end{proof}

\subsection{Nash Equilibrium Analysis}

\subsubsection{Incentive Compatibility}

We prove that honest reporting constitutes a Nash equilibrium by showing that no player can unilaterally improve their utility by deviating from the honest strategy when all other players follow it.

\begin{theorem}
\textbf{Nash Equilibrium}: When all other nodes behave honestly, the optimal strategy for any individual node is to also behave honestly.
\end{theorem}

\begin{proof}
Consider a node $n_i$ in a network where all other nodes follow honest strategies. The expected utility for $n_i$ under different strategies:

\textbf{Honest Strategy:} $U_H = R_{reward} - C_{commit}$

\textbf{Malicious Strategy:} $U_M = B_{attack} - C_{stake} - C_{commit} - P_{slash} \cdot p_{detection}$

Where $p_{detection} \approx 1$ due to our multi-layer verification system.

Since $P_{slash} \gg B_{attack}$ and $C_{stake} > 0$, we have $U_H > U_M$.

\textbf{Lazy Strategy:} $U_L = -C_{commit} - R_{penalty}$

Since $R_{penalty} > 0$, we have $U_H > U_L$.

Therefore, $U_H > U_M$ and $U_H > U_L$, proving that honest behavior is optimal when others behave honestly.
\end{proof}

\subsubsection{Economic Incentive Alignment}

The OraSRS protocol aligns economic incentives with security objectives:

\begin{enumerate}
\item \textbf{Positive Incentives}: Honest nodes receive rewards for accurate threat reporting
\item \textbf{Negative Incentives}: Malicious nodes face substantial penalties via slashing
\item \textbf{Reputation Effects}: Long-term reputation impacts future reward opportunities
\end{enumerate}

This alignment changes the economic motivations of potential attackers from "what can I gain from attacking" to "what do I risk losing by attacking", fundamentally altering the attack calculus.

\subsection{Attack Resistance Analysis}

\subsubsection{Sybil Attack Resistance}

The protocol resists Sybil attacks through multiple mechanisms:

\begin{itemize}
\item \textbf{Stake-based Weighting}: Voting power is proportional to stake, not node count
\item \textbf{Reputation System}: Long-term reputation provides additional weight
\item \textbf{Behavioral Analysis}: Anomaly detection identifies coordinated malicious behavior
\end{itemize}

\subsubsection{Economic Analysis of Sybil Resistance}

Let $n$ be the number of honest nodes with total stake $S_H$, and $k$ be the number of Sybil nodes created by an attacker with stake $S_A$. The attacker's influence is bounded by:

$$\text{Influence} = \frac{S_A}{S_H + S_A}$$

Since creating Sybil nodes doesn't increase $S_A$, the attacker's influence remains bounded regardless of the number of fake identities created.

\subsubsection{Collusion Resistance}

The protocol is designed to detect and mitigate colluding nodes:

$$P(\text{collusion detection}) = f(\text{behavioral similarity}, \text{temporal correlation}, \text{reputation history})$$

Where $f$ is a function designed to identify coordinated malicious behavior among validators.
